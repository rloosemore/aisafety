# AI Policy, Legislation, and Democratic Governance Landscape

*Research compiled February 2026 for AISafety.org*

> The global AI policy landscape is in a period of rapid, uneven, and often contradictory development. Some jurisdictions are building comprehensive regulatory frameworks while others are actively dismantling oversight. This document maps the terrain and identifies where citizens can intervene.

---

## Table of Contents

1. [Major AI Legislation](#1-major-ai-legislation)
2. [Worker-Protective Legislation](#2-worker-protective-legislation)
3. [Democratic AI Governance](#3-democratic-ai-governance)
4. [Corporate Accountability](#4-corporate-accountability)
5. [International Coordination](#5-international-coordination)
6. [How to Take Political Action](#6-how-to-take-political-action)
7. [What's Missing: Gaps, Failures, and Risks](#7-whats-missing-gaps-failures-and-risks)

---

## 1. Major AI Legislation

### European Union: The AI Act

The EU AI Act is the most comprehensive AI legislation in the world. It entered into force on August 1, 2024, with a phased enforcement timeline.

**Enforcement Timeline:**

| Date | Milestone |
|------|-----------|
| **Feb 2, 2025** | Prohibited practices ban takes effect; AI literacy requirements begin |
| **Aug 2, 2025** | GPAI model provider obligations; penalty regime active (up to EUR 35M or 7% global turnover); AI Office operational; Member States must designate national competent authorities |
| **Aug 2, 2026** | Majority of rules apply: high-risk AI systems (Annex III), transparency rules (Article 50), full enforcement at national and EU level |
| **Aug 2, 2027** | Full scope applies to all risk categories including Annex II (medium-to-high-risk) |

**Eight Prohibited Practices (effective Feb 2025):**
1. Subliminal manipulation that distorts behavior and impairs informed decision-making
2. Exploitation of vulnerabilities (age, disability, socio-economic status) to influence behavior
3. Social scoring systems that evaluate people based on social behavior or personal traits
4. Predictive policing based solely on social interactions or personality
5. Untargeted scraping of the internet or CCTV to build facial recognition databases
6. Emotion recognition in workplaces and educational institutions
7. Biometric categorization to deduce protected characteristics
8. Real-time remote biometric identification in public spaces for law enforcement

**Note:** The EU's Digital Omnibus may delay some high-risk obligations, with long-stop dates potentially pushed to December 2027 or August 2028.

Sources:
- [EU AI Act Implementation Timeline](https://artificialintelligenceact.eu/implementation-timeline/)
- [DLA Piper: EU AI Act Prohibited Practices](https://www.dlapiper.com/en/insights/publications/ai-outlook/2025/eu-ai-acts-ban-on-prohibited-practices-takes-effect)
- [Orrick: 6 Steps Before August 2026](https://www.orrick.com/en/Insights/2025/11/The-EU-AI-Act-6-Steps-to-Take-Before-2-August-2026)
- [AlgorithmWatch: Prohibited AI Applications](https://algorithmwatch.org/en/ai-act-prohibitions-february-2025/)
- [LegalNodes: EU AI Act 2026 Updates](https://www.legalnodes.com/article/eu-ai-act-2026-updates-compliance-requirements-and-business-risks)

---

### United States: Federal Level

The US lacks a single comprehensive federal AI law. The landscape is shaped by executive orders, agency enforcement, and a growing patchwork of state laws.

**Key Executive Actions:**
- **Jan 2025:** Executive Order 14179 (Trump administration) rescinded several Biden-era AI safety measures and transparency requirements, directing development of an "AI Action Plan" while ordering federal agencies to eliminate "ideological bias" in AI regulation
- **Dec 2025:** Executive Order "Ensuring a National Policy Framework for Artificial Intelligence" directed the federal government to review state laws deemed "inconsistent" with national AI policy framework, signaling potential federal preemption of state regulation

**Major Federal Bills (119th Congress, 2025-2026):**
- **AI PLAN Act (H.R. 2152):** Addresses AI in financial crimes and fraud defense
- **CREATE AI Act (H.R. 2385):** Establishes the National Artificial Intelligence Research Resource for broader access to computational resources
- **READ AI Models Act (H.R. 6461):** Directs NIST to develop best practices for AI model documentation
- **GAIN AI Act (S. 3150):** Addresses export controls for advanced AI chips
- **AI for America Act (H.R. 6304):** Codifies national AI strategy, focuses on removing regulatory barriers
- **Algorithmic Accountability Act of 2025** (Rep. Yvette Clarke): Transparency and accountability requirements for AI in housing, employment, credit, education

**The critical dynamic:** The federal government is pushing a pro-innovation, deregulatory agenda while simultaneously signaling it may preempt stronger state-level protections.

Sources:
- [NCSL: AI 2025 Legislation](https://www.ncsl.org/technology-and-communication/artificial-intelligence-2025-legislation)
- [Drata: AI Regulations 2026](https://drata.com/blog/artificial-intelligence-regulations-state-and-federal-ai-laws-2026)
- [Congress.gov: AI Bills](https://www.congress.gov/bill/119th-congress/house-bill/2152/text)
- [Rep. Clarke: Algorithmic Accountability Act](https://clarke.house.gov/clarke-introduces-bill-to-regulate-ais-control-over-critical-decision-making-in-housing-employment-education-and-more/)

---

### United States: State-Level Laws

In 2025, all 50 states introduced AI-related legislation, with 1,208 bills introduced and 145 enacted. States have become the primary architects of US AI regulation.

**Colorado AI Act (SB 24-205)**
- First comprehensive state AI law addressing algorithmic discrimination
- Effective date delayed to **June 30, 2026**
- Requires impact assessments, risk management programs, public disclosure of AI system types
- Mandates notification to workers when AI is used in employment decisions
- Requires opportunity to appeal AI-driven decisions
- [Source](https://natlawreview.com/article/several-state-ai-laws-set-go-effect-2026-despite-federal-governments-push-eliminate)

**Illinois HB 3773**
- Requires all Illinois employers to notify employees and applicants when AI is used in employment decisions
- Effective **January 1, 2026**
- Applies to any employer with at least one employee in Illinois
- [Source](https://www.hunton.com/insights/publications/the-evolving-landscape-of-ai-employment-laws-what-employers-should-know-in-2025)

**California**
- **SB 53** (signed into law, effective Jan 1, 2026): Requires "large frontier developers" (>$500M revenue, models at 10^26+ FLOPs) to publish transparency reports, safety testing documentation, and report critical safety incidents within 15 days (24 hours if imminent harm)
- **CCPA Automated Decision-Making Regulations** (effective Jan 1, 2027): Right to opt out of automated decision-making for "significant decisions" (housing, employment, credit, healthcare)
- Civil Rights Council employment regulations (effective Oct 2025): Confirms AI-driven employment discrimination violates state anti-discrimination laws
- [Source: Fisher Phillips](https://www.fisherphillips.com/en/news-insights/california-lawmakers-pass-landmark-ai-transparency-law-for-frontier-models.html)
- [Source: Latham & Watkins](https://www.lw.com/en/insights/california-assumes-role-as-lead-us-regulator-of-ai)

**Texas RAIGA (HB 149)**
- Effective January 1, 2026
- Minimal requirements on private employers; focuses primarily on government agencies
- [Source](https://www.kslaw.com/news-and-insights/new-state-ai-laws-are-effective-on-january-1-2026-but-a-new-executive-order-signals-disruption)

**New York City Local Law 144**
- In force since July 2023; requires annual independent bias audits of automated employment decision tools (AEDTs)
- Employers must give candidates 10 business days' notice before using AEDTs
- Audit results must be publicly posted
- Penalties: $500-$1,500 per day for violations
- **Enforcement challenges:** A December 2025 audit by the NY State Comptroller found the city had trouble identifying non-compliance, especially when employers failed to disclose AI use
- [Source: NYC DCWP](https://www.nyc.gov/site/dca/about/automated-employment-decision-tools.page)
- [Source: NY Comptroller](https://www.osc.ny.gov/press/releases/2025/12/dinapoli-new-yorkers-deserve-transparent-hiring-process-when-artificial-intelligence-used-vet-their)

**Tracking Resources:**
- [NCSL AI Legislation Database](https://www.ncsl.org/financial-services/artificial-intelligence-legislation-database) (updated monthly)
- [IAPP US State AI Governance Tracker](https://iapp.org/resources/article/us-state-ai-governance-legislation-tracker) (updated Feb 2026)
- [MultiState AI Legislation Tracker](https://www.multistate.ai/artificial-intelligence-ai-legislation)

---

### United Kingdom

The UK has taken a principles-based, sector-led approach rather than enacting a single comprehensive law like the EU AI Act.

**Current Framework:**
- Five core principles implemented by existing sector regulators (FCA, CMA, Information Commissioner, etc.)
- No standalone AI legislation in force as of early 2026
- **AI Growth Lab** (proposed Oct 2025): Supervised regulatory sandboxes to test AI in healthcare, professional services, transport, and manufacturing
- **UK AI Bill:** Delayed until summer 2026 at earliest; expected after King's Speech (May 2026 or later)
- Artificial Intelligence (Regulation) Private Members' Bill re-introduced in the House of Lords (March 2025) but lacks government backing

Sources:
- [White & Case: UK AI Tracker](https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-united-kingdom)
- [Taylor Wessing: UK 2026 Predictions](https://www.taylorwessing.com/en/interface/2025/predictions-2026/uk-tech-and-digital-regulatory-policy-in-2026)
- [Slaughter and May: AI 2026 Update](https://www.slaughterandmay.com/horizon-scanning/2026/digital/ai-update-for-2026/)

---

### China

China has moved aggressively on AI regulation through targeted, sectoral rules rather than a single comprehensive law.

**Key Regulations:**
- **Deep Synthesis Regulations** (Jan 2023): Governs AI-generated video, voice, text, image, and synthetic content
- **Generative AI Interim Measures** (Aug 2023): First binding generative AI regulation in the world; requires content legality, truthfulness, labeling, and algorithm registration
- **Content Labeling Rules** (Sep 1, 2025): Mandatory implicit labeling of AI-generated content, with explicit labeling where applicable
- **Three National AI Security Standards** (Nov 1, 2025): Standardized AI security and governance requirements
- **Cybersecurity Law Amendment** (Jan 1, 2026): Brings AI into national law for the first time; framework for AI safety, foundational research, infrastructure, and ethical standards

**Enforcement:** In April 2025, China launched a nationwide campaign ("Clear and Bright") resulting in 3,500+ AI products taken down, 960,000+ illegal content pieces removed, and 3,700+ accounts penalized.

**Future direction:** China removed a comprehensive AI law from its 2025 agenda, prioritizing pilots, standards, and targeted rules to manage risks while keeping compliance costs low.

Sources:
- [White & Case: China AI Tracker](https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-china)
- [East Asia Forum: China AI Governance](https://eastasiaforum.org/2025/12/25/china-resets-the-path-to-comprehensive-ai-governance/)
- [Securiti: China AI Landscape 2025](https://securiti.ai/china-ai-regulatory-landscape/)

---

### Canada

Canada's proposed Artificial Intelligence and Data Act (AIDA), part of Bill C-27, **died on the order paper in January 2025** when Parliament was prorogued. The current government has indicated it will regulate AI through privacy legislation, policy, and investment rather than pursuing overarching AI-specific legislation.

Sources:
- [Montreal AI Ethics Institute: Death of AIDA](https://montrealethics.ai/the-death-of-canadas-artificial-intelligence-and-data-act-what-happened-and-whats-next-for-ai-regulation-in-canada/)
- [Schwartz Reisman Institute: What's Next After AIDA](https://srinstitute.utoronto.ca/news/whats-next-for-aida)

---

### Japan

Japan's Parliament approved the **Act on the Promotion of Research and Development and the Utilization of AI-Related Technologies** on May 28, 2025, making Japan the second major Asia-Pacific economy to enact comprehensive AI legislation. Most provisions took effect June 4, 2025.

Key features:
- Foundational policy statute (not prescriptive compliance code)
- Innovation-first approach: emphasizes research funding, cooperation, voluntary guidelines
- Created **AI Strategic Headquarters** (led by Prime Minister, includes all Cabinet ministers), operational late 2025
- AI Basic Plan expected to be approved by Cabinet by end of 2025

Sources:
- [FPF: Japan AI Promotion Act](https://fpf.org/blog/understanding-japans-ai-promotion-act-an-innovation-first-blueprint-for-ai-regulation/)
- [AI News Desk: Japan AI Regulation 2026](https://ainewsdesk.app/japan-ai-regulation-2026/)

---

### Australia

Australia currently relies on **existing regulatory frameworks** and voluntary standards rather than AI-specific legislation. The government released a Voluntary AI Safety Standard (August 2024) and a responsible use policy (September 2024), but experts warn Australia may be falling behind.

Source: [Mind Foundry: AI Regulations Around the World](https://www.mindfoundry.ai/blog/ai-regulations-around-the-world)

---

## 2. Worker-Protective Legislation

### AI in Employment Decisions

Multiple US states are enacting laws specifically addressing AI's role in hiring, firing, and workplace management.

**Laws Taking Effect in 2026:**

| Jurisdiction | Law | Effective Date | Key Requirements |
|---|---|---|---|
| Colorado | SB 24-205 | June 30, 2026 | Impact assessments, worker notification, appeal rights, public disclosure |
| Illinois | HB 3773 | Jan 1, 2026 | Mandatory notification when AI used in employment decisions |
| Texas | RAIGA (HB 149) | Jan 1, 2026 | Requirements for government agencies; minimal private-sector obligations |
| California | CCPA ADMT Regs | Jan 1, 2027 | Right to opt out of automated significant decisions; record retention (4 years) |
| California | Civil Rights Council Regs | Oct 1, 2025 | AI-driven employment discrimination violates anti-discrimination law |
| NYC | Local Law 144 | In force (2023) | Annual bias audits, candidate notification, public results posting |

**Human Review Rights:**
Across nearly all enacted and proposed regimes, human review remains a central risk-mitigation strategy. Key provisions include:
- Colorado requires opportunity to appeal AI-driven decisions
- California CCPA regulations provide right to opt out of automated decision-making for significant decisions
- NYC Local Law 144 requires employers to offer alternative assessment methods upon request
- The EU AI Act requires human oversight for high-risk AI systems

Sources:
- [K&L Gates: AI Employment Landscape 2026](https://www.klgates.com/Navigating-the-AI-Employment-Landscape-in-2026-Considerations-and-Best-Practices-for-Employers-2-2-2026)
- [Hunton: AI Employment Laws 2025](https://www.hunton.com/insights/publications/the-evolving-landscape-of-ai-employment-laws-what-employers-should-know-in-2025)
- [Harvard Journal on Legislation: Regulating AI in the Workplace](https://journals.law.harvard.edu/jol/2025/12/06/the-sound-and-fury-of-regulating-ai-in-the-workplace/)

---

### Automation Tax / Robot Tax Proposals

**Senator Bernie Sanders' Robot Tax Bill:**
Sanders plans to formally introduce a "robot tax" bill, arguing that AI and robotics investments must benefit working people, not just the billionaire class. Senate Democrats published a report claiming AI and automation could destroy nearly 100 million US jobs in a decade.

**New York State:** Legislators have introduced bills (2023 and 2025) to tax businesses that displace workers through automation.

**Alternative Approaches:**
- **New Jersey:** Proposed rewards for businesses hiring displaced workers and AI skills apprenticeships
- **Utah:** Enacted grants for AI career education business partnerships (2024)
- **Ohio:** Created grants for community colleges to offer AI training (2025)

**Criticisms:** Policy experts argue robot taxes face definitional challenges (what counts as automation?), may become obsolete quickly as technology evolves, and excise-tax structures risk passing costs to consumers.

Sources:
- [Brookings: Case for a Robot Tax](https://www.brookings.edu/articles/navigating-the-future-of-work-a-case-for-a-robot-tax-in-the-age-of-ai/)
- [Tax Notes: Robot Tax Proposals](https://www.taxnotes.com/featured-analysis/robot-tax-proposals-legislative-review/2025/11/20/7t92q)
- [Reason: Robot Tax Criticism](https://reason.com/2025/10/07/democrats-are-proposing-a-robot-tax-to-save-jobs-from-ai-heres-why-it-wont-work/)
- [Bloomberg Law: Statehouse AI Job-Loss Solutions](https://news.bloomberglaw.com/daily-labor-report/statehouse-ai-job-loss-solutions-range-from-punitive-to-positive)

---

## 3. Democratic AI Governance

### Citizen Assemblies on AI

**Germany (North Rhine-Westphalia):** A Citizens' Assembly of 80 randomly selected residents will convene from April 17 to June 23, 2026, focusing on how digital progress and AI can support self-determined life and cross-generational public services.

**Global Citizens' Assembly on AI:** Planned to start deliberations in early 2026, organized by the Global Coalition for Inclusive AI Governance (launched February 2025), aiming to bring together more than 10,000 citizens worldwide.

**California:** In February 2025, announced a new deliberative democracy program and platform, with Carnegie California playing a collaborative role.

**Fort Collins, Colorado:** AI-enabled analysis helped the city engage with 4,000+ long-form responses on a contested land-use issue, demonstrating AI-enhanced public participation.

Sources:
- [German Citizens' Assembly](https://www.buergerrat.de/en/news/citizens-assembly-on-public-services-with-ai/)
- [DemocracyNext: Citizen-led AI Governance](https://www.demnext.org/projects/ai-governance)
- [Carnegie Endowment: AI and Public Wisdom](https://carnegieendowment.org/posts/2025/07/how-ai-can-unlock-public-wisdom-and-revitalize-democratic-governance)
- [OECD: AI in Civic Participation](https://www.oecd.org/en/publications/2025/06/governing-with-artificial-intelligence_398fa287/full-report/ai-in-civic-participation-and-open-government_51227ce7.html)

---

### Municipal AI Governance

**Amsterdam Algorithm Register:** One of the first city-level algorithm registries in the world, making all government algorithms transparent and open to public scrutiny.

**Helsinki:** Co-pioneered the algorithm register concept alongside Amsterdam.

**Barcelona Municipal AI Strategy:** Seven governing principles (human supervision; technical robustness; data privacy; transparency; diversity and inclusion; social/environmental commitment; accountability and democratic control). Creating a public algorithm register accessible to all citizens.

**Eurocities Collaborative Standard:** Barcelona, Bologna, Brussels Capital Region, Eindhoven, Mannheim, Rotterdam, and Sofia developed an open-source data schema based on the Amsterdam/Helsinki model, enabling any city to create its own algorithm registry using a common standard.

Sources:
- [OECD.AI: Amsterdam Algorithm Register](https://oecd.ai/en/catalogue/tools/algorithm-register-in-the-city-of-amsterdam)
- [Barcelona Digital City: Municipal AI Strategy](https://ajuntament.barcelona.cat/digital/en/technology-accessible-everyone/ethical-use-artificial/ethical-use-artificial-intelligence/municipal)
- [Algorithm Register Guidance for European Cities](https://www.algorithmregister.org/guidance)

---

### The "Democratic AI" Movement

Key organizations driving this work:
- **DemocracyNext:** Projects specifically on citizen-led AI governance
- **People Powered:** Global hub for citizens' assemblies and participatory governance
- **Carnegie Endowment:** Research on AI-enhanced democratic participation
- **Go Vocal:** Tracks public participation trends including hybrid democracy models

**Critical Perspective:** Some researchers warn that using AI to "enhance" democratic participation risks technosolutionism, where technology solutions reinforce depoliticization rather than genuine democratic engagement.

Sources:
- [Go Vocal: Public Participation Trends 2026](https://www.govocal.com/trends-report-2026)
- [Yale ISPS: Reimagining Democracy](https://isps.yale.edu/news/blog/2026/01/reimagining-democracy-yale-hosts-global-experts-on-ai-governance-and-the-future-of)
- [Journal of Deliberative Democracy: AI Technosolutionism](https://delibdemjournal.org/article/id/1839/)

---

## 4. Corporate Accountability

### Transparency and Audit Requirements

**EU AI Act (from Aug 2026):**
- High-risk AI systems must undergo conformity assessments
- Providers must maintain technical documentation, quality management systems, and post-market monitoring
- Transparency obligations for certain AI systems (chatbots, deepfakes, emotion recognition)

**Colorado AI Act (from June 2026):**
- Developers and deployers must conduct algorithmic impact assessments
- Risk management policies and programs required
- Public statements on AI system types and discrimination risk management

**California SB 53 (from Jan 2026):**
- Large frontier developers must publish "frontier AI frameworks" explaining risk assessment and mitigation
- Critical safety incident reporting (15 days, or 24 hours for imminent harm)

**NYC Local Law 144 (in force):**
- Annual independent bias audits
- Public posting of audit results and dates

**International Standards:**
- **ISO/IEC 42001:** First management system standard for AI, providing a certifiable framework for governing AI across its lifecycle; increasingly appearing in procurement requirements

Sources:
- [AI Now Institute: Algorithmic Accountability](https://ainowinstitute.org/publications/algorithmic-accountability)
- [Wilson Sonsini: 2026 AI Regulatory Preview](https://www.wsgr.com/en/insights/2026-year-in-preview-ai-regulatory-developments-for-companies-to-watch-out-for.html)

---

### Shareholder Activism and AI

AI has become a core governance concern for institutional investors:
- Over **31% of S&P 500 companies** disclosed board oversight of AI in 2024
- AI-related shareholder proposals focus on social issues: human rights, labor rights, child safety, data usage, misinformation, workforce impacts
- Exempt solicitations (a low-cost activism mechanism) surged from 168 in 2018 to 414 in 2024
- Growing expectation that boards establish formal AI oversight committees or integrate AI risk into existing governance structures

**ESG Trend Note:** Average support for ESG proposals has dropped from 35% (2021) to ~20% (early 2025), but 68% of survey respondents still align with ESG-driven campaigns.

Sources:
- [Harvard Law: AI Shareholder Proposals 2022-2025](https://corpgov.law.harvard.edu/2025/12/22/a-look-at-ai-related-shareholder-proposals-at-u-s-companies-2022-2025/)
- [Harvard Law: AI and Shareholder Activism](https://corpgov.law.harvard.edu/2025/04/16/ai-identity-driven-shareholder-activism-and-the-future-of-corporate-governance/)
- [Norton Rose Fulbright: Rise in AI Shareholder Proposals](https://www.nortonrosefulbright.com/en/knowledge/publications/2c0ceaa9/the-rise-in-ai-shareholder-proposals-navigating-shareholder-concerns)

---

## 5. International Coordination

### AI Safety Summit Series

| Summit | Date | Location | Key Outcomes |
|---|---|---|---|
| **AI Safety Summit** | Nov 2023 | Bletchley Park, UK | Bletchley Declaration (28 countries including US and China); creation of first AI Safety Institutes (AISIs); commissioned "State of the Science" report |
| **AI Seoul Summit** | May 2024 | Seoul, South Korea | Seoul Declaration (27 nations + EU); 10 countries + EU pledged to establish AI Safety Institutes and international network |
| **AI Action Summit** | Feb 2025 | Paris, France | International AI Safety Report published; Current AI launched with $400M for public-interest AI; environmental sustainability coalition (91 partners). But criticized as a "missed opportunity" on safety by Anthropic CEO Dario Amodei |
| **AI Impact Summit** | Feb 2026 | Delhi, India | Upcoming |

Sources:
- [Future of Life Institute: AI Safety Summits](https://futureoflife.org/project/ai-safety-summits/)
- [techUK: Paris AI Summit Outcomes](https://www.techuk.org/resource/what-were-the-outcomes-of-the-paris-ai-action-summit.html)
- [RUSI: What Comes After Paris](https://www.rusi.org/explore-our-research/publications/commentary/what-comes-after-paris-ai-summit)
- [EPC: Paris Summit Analysis](https://www.epc.eu/publication/The-Paris-Summit-Au-Revoir-global-AI-Safety-61ea68/)

---

### UN Efforts

**High-Level Advisory Body on AI** released its Final Report, "Governing AI for Humanity" (September 2024), with seven proposals:
1. International Scientific Panel on AI (annual reports on capabilities, risks, trends)
2. Policy dialogue on AI governance within the UN (intergovernmental + multi-stakeholder)
3. AI Standards Exchange for technical interoperability
4. Global AI Capacity Network (training, compute, datasets)
5. Global AI Fund for capacity-building
6. Global AI Data Framework for standardized definitions and principles
7. Small AI Office within the UN Secretariat

Sources:
- [UN AI Advisory Body](https://www.un.org/en/ai-advisory-body)
- [UN: Governing AI for Humanity](https://www.un.org/digital-emerging-technologies/ai-advisory-body)
- [CDO Magazine: UN 7 Recommendations](https://www.cdomagazine.tech/aiml/un-advisory-bodys-7-key-recommendations-for-global-ai-governance)

---

### OECD AI Principles

Five core principles (adopted 2019, updated since):
1. Inclusive growth, sustainable development, and well-being
2. Respect for rule of law, human rights, democratic values, fairness, privacy
3. Transparency and explainability
4. Robustness, security, and safety
5. Accountability

Adopted by G20 members. Influenced the EU AI Act and NIST AI Risk Management Framework. OECD published common framework for AI incident reporting (February 2025).

**G20 Task Force on AI:** First meeting of G20 Task Force on AI, Data Governance, and Innovation for Sustainable Development held February 2025.

Sources:
- [OECD AI Principles](https://oecd.ai/en/ai-principles)
- [White & Case: OECD AI Tracker](https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-oecd)

---

### Coordination Problems

The fundamental challenge of international AI coordination:
- **US-China divergence:** Both signed the Bletchley Declaration but have fundamentally different governance philosophies
- **Regulatory fragmentation:** EU, US, UK, China, Japan all taking different approaches, creating compliance complexity
- **Speed mismatch:** International coordination moves slowly while AI capabilities advance rapidly
- **Enforcement gaps:** Cross-border cooperation is essential but mechanisms are weak
- **Voluntary vs. binding:** Most international agreements are non-binding; enforcement depends on national implementation

---

## 6. How to Take Political Action

### Contact Your Representatives

**In the US:**
- Find your representatives: [congress.gov](https://www.congress.gov/members/find-your-member)
- Call or write about specific AI bills (listed above)
- State-level engagement matters most right now since states are the primary AI regulators
- Find your state legislators: [openstates.org](https://openstates.org/)

**Key messages to communicate:**
- Support for algorithmic accountability and transparency requirements
- Demand human review rights for AI-driven decisions affecting employment, credit, housing
- Push back on federal preemption of stronger state protections
- Support funding for AI safety research and enforcement

---

### Organizations Tracking and Pushing AI Policy

| Organization | Focus | Website |
|---|---|---|
| **Algorithmic Justice League** | AI bias, fairness, policy advocacy | [ajl.org](https://www.ajl.org/) |
| **AI Now Institute** | AI social implications, accountability research | [ainowinstitute.org](https://ainowinstitute.org/) |
| **Electronic Frontier Foundation** | Digital civil liberties, AI policy | [eff.org/issues/ai](https://www.eff.org/issues/ai) |
| **Partnership on AI** | Multi-stakeholder best practices | [partnershiponai.org](https://partnershiponai.org/) |
| **Future of Life Institute** | Existential risk, AI safety summits | [futureoflife.org](https://futureoflife.org/) |
| **Center for AI Safety** | AI safety research and advocacy | [safe.ai](https://www.safe.ai/) |
| **AlgorithmWatch** | Algorithmic accountability, EU policy | [algorithmwatch.org](https://algorithmwatch.org/) |
| **IAPP** | Privacy and AI governance tracking | [iapp.org](https://iapp.org/) |
| **TechPolicy.Press** | Independent AI policy journalism | [techpolicy.press](https://www.techpolicy.press/) |
| **DemocracyNext** | Citizen-led AI governance | [demnext.org](https://www.demnext.org/) |

---

### Public Comment Periods

Public comment periods (typically 30-60 days) are one of the most direct ways to influence AI regulation. When agencies propose new rules, you can submit written comments.

**Where to find them:**
- **US Federal:** [regulations.gov](https://www.regulations.gov/) (search "artificial intelligence")
- **EU:** [Have Your Say portal](https://ec.europa.eu/info/law/better-regulation/have-your-say_en)
- **State level:** Check your state legislature's website for open comment periods on AI bills

**Tips for effective comments:**
- Reference specific provisions of proposed rules
- Describe real-world impacts on workers, communities, or rights
- Cite research and evidence
- Personal stories are powerful, especially about AI-driven employment decisions, discrimination, or surveillance
- Submit early in the comment period (agencies pay more attention to early comments)

---

### Upcoming Opportunities (2026)

- **Colorado AI Act implementation** (June 30, 2026): Engage with Colorado's rulemaking process
- **EU AI Act high-risk rules** (August 2, 2026): Comment on implementation guidance
- **UK AI Bill** (expected summer 2026): Engage during consultation period
- **AI Impact Summit in Delhi** (February 2026): Push for stronger binding commitments
- **California CCPA ADMT regulations** (effective Jan 1, 2027): Comment period may still be open
- **Federal AI Action Plan review:** Track Commerce Department evaluations of state AI measures

---

### Supporting Specific Bills

**Bills worth supporting (US):**
- **Algorithmic Accountability Act of 2025:** Comprehensive transparency and accountability for AI in high-impact decisions
- **Colorado AI Act enforcement:** Push for strong implementation without further delays
- **Illinois HB 3773:** Model for other states on employer notification requirements
- **State-level AI bills:** Check NCSL and IAPP trackers for your state

**What to push for that doesn't yet exist:**
- Federal floor (not ceiling) for AI protections that allows states to go further
- Dedicated AI enforcement agencies with technical expertise and adequate funding
- Mandatory algorithmic impact assessments for all high-risk AI systems
- Worker right to organize around AI deployment decisions
- Public access to algorithmic audit results

---

## 7. What's Missing: Gaps, Failures, and Risks

### The Speed Mismatch

AI capabilities are advancing faster than regulatory frameworks can respond. Even the EU AI Act, the most comprehensive legislation, was negotiated over years and uses technical thresholds (like compute levels) that may become obsolete. Basic definitional questions ("What counts as AI?") vary by jurisdiction and cannot keep up with the technology.

### Regulatory Capture

The Trump administration's Executive Order 14179 explicitly aligns US regulatory posture with AI industry commercial interests. Tech industry PACs are spending millions to shape regulatory agendas. The revolving door between tech companies and regulatory agencies creates structural conflicts of interest. Even in the EU, industry lobbying significantly shaped the AI Act's final text.

Source: [Oxford Law: AI Regulation and Regulatory Capture](https://blogs.law.ox.ac.uk/oblb/blog-post/2025/06/ai-regulation-politics-fragmentation-and-regulatory-capture)

### The Preemption Threat

The December 2025 Executive Order directing review of state laws "inconsistent" with federal AI policy signals potential federal preemption of the very state laws that currently provide the strongest protections. This could eliminate Colorado, Illinois, California, and other state-level protections before they are fully implemented.

### Enforcement Gaps

- **NYC Local Law 144** demonstrates the enforcement problem: even when laws exist, regulators struggle to identify non-compliance, especially when companies don't disclose AI use
- Many jurisdictions lack the technical expertise to meaningfully audit AI systems
- Cross-border enforcement remains nearly impossible
- Penalty structures may be too low to deter large tech companies (though the EU's 7% global turnover threshold is an exception)

### The Patchwork Problem

Without federal harmonization, the US faces a patchwork of overlapping, conflicting, and sometimes ambiguous state obligations. Companies face compliance complexity; citizens face unequal protection depending on their state. The risk is that this complexity becomes an argument for weak federal preemption rather than strong federal floors.

### What's Still Unregulated

- **General-purpose AI systems** are largely unregulated outside the EU
- **AI in surveillance** (beyond biometrics) has minimal regulation in most jurisdictions
- **AI and environmental impact** (compute energy use, resource consumption) lacks binding regulation
- **AI-driven market concentration** and monopoly power remain unaddressed by AI-specific laws
- **AI in military and autonomous weapons** governed by voluntary norms only
- **AI-generated misinformation** addressed in China but largely unregulated in Western democracies
- **AI's impact on creative workers** (beyond copyright) has no dedicated legislative framework
- **Algorithmic pricing and consumer manipulation** (dynamic pricing, dark patterns) are poorly covered

### The Fundamental Gap

The biggest gap is democratic. AI systems that affect millions of people's employment, credit, housing, and freedom are being developed and deployed with minimal public input. Citizen assemblies and participatory processes exist but reach a tiny fraction of the affected population. The organizations best positioned to shape AI regulation (major tech companies) are also the entities being regulated, creating a structural imbalance that no current governance framework adequately addresses.

---

## Key Takeaways for Action

1. **The EU AI Act is the global standard-setter.** Its enforcement timeline through 2027 will shape corporate behavior worldwide. Push for strong implementation and resist lobbying to weaken it.

2. **US state laws are the frontline.** With federal regulation stalled or hostile, Colorado, Illinois, California, and others are where the real protections are being built. Support these laws and push back against federal preemption.

3. **Worker protections are emerging but incomplete.** Right-to-notification and bias-audit requirements are a start, but workers need stronger rights: to organize around AI deployment, to appeal AI decisions with meaningful human review, and to share in productivity gains.

4. **Democratic governance of AI is still embryonic.** Citizens' assemblies, algorithm registers, and participatory processes exist but need massive scaling. Support organizations like DemocracyNext and demand your city create an algorithm register.

5. **International coordination is fragile.** The AI Safety Summit series has produced declarations but few binding commitments. The Delhi summit in 2026 is the next opportunity to push for stronger international mechanisms.

6. **Enforcement is the weakest link.** Even where good laws exist, enforcement capacity is minimal. Push for dedicated AI enforcement agencies with technical expertise and adequate funding.

7. **The window for action is now.** Multiple laws take effect in 2026, and the shape of AI regulation for the next decade is being determined in legislatures, agencies, and international forums right now. Engage with public comment periods, contact representatives, and support organizations doing this work.

---

*This document will be updated as the legislative landscape evolves. Last updated: February 2026.*
